{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from rouge_score import rouge_scorer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Flask in c:\\users\\kamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.0.2)\n",
      "Requirement already satisfied: transformers in c:\\users\\kamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.37.2)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\users\\kamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from Flask) (3.0.1)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\kamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from Flask) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\kamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from Flask) (2.1.2)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\kamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from Flask) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\kamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from Flask) (1.7.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\kamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\kamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\kamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\kamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\kamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in c:\\users\\kamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\kamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\kamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\kamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\kamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from click>=8.1.3->Flask) (0.4.6)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\kamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\kamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from Jinja2>=3.1.2->Flask) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install Flask transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting FlaskNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading flask-3.0.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting Werkzeug>=3.0.0 (from Flask)\n",
      "  Downloading werkzeug-3.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\kamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from Flask) (3.1.3)\n",
      "Collecting itsdangerous>=2.1.2 (from Flask)\n",
      "  Downloading itsdangerous-2.1.2-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\kamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from Flask) (8.1.7)\n",
      "Collecting blinker>=1.6.2 (from Flask)\n",
      "  Downloading blinker-1.7.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\kamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from click>=8.1.3->Flask) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kamal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from Jinja2>=3.1.2->Flask) (2.1.5)\n",
      "Downloading flask-3.0.2-py3-none-any.whl (101 kB)\n",
      "   ---------------------------------------- 0.0/101.3 kB ? eta -:--:--\n",
      "   ------------------------ --------------- 61.4/101.3 kB 1.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 92.2/101.3 kB 1.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- 101.3/101.3 kB 968.7 kB/s eta 0:00:00\n",
      "Downloading blinker-1.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "Downloading werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
      "   ---------------------------------------- 0.0/226.7 kB ? eta -:--:--\n",
      "   ---------- ----------------------------- 61.4/226.7 kB ? eta -:--:--\n",
      "   -------------- ------------------------- 81.9/226.7 kB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  225.3/226.7 kB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 226.7/226.7 kB 1.7 MB/s eta 0:00:00\n",
      "Installing collected packages: Werkzeug, itsdangerous, blinker, Flask\n",
      "Successfully installed Flask-3.0.2 Werkzeug-3.0.1 blinker-1.7.0 itsdangerous-2.1.2\n"
     ]
    }
   ],
   "source": [
    "pip install Flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kamal\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = '''\n",
    "The majority of available text summarization datasets include short-form source documents that lack \n",
    "long-range causal and temporal dependencies, and often contain strong layout and stylistic biases. While relevant, \n",
    "such datasets will offer limited challenges for future generations of text summarization systems. We address these \n",
    "issues by introducing BookSum, a collection of datasets for long-form narrative summarization. Our dataset covers \n",
    "source documents from the literature domain, such as novels, plays and stories, and includes highly abstractive, \n",
    "human written summaries on three levels of granularity of increasing difficulty: paragraph-, chapter-, and book-level.\n",
    " The domain and structure of our dataset poses a unique set of challenges for summarization systems, which include:\n",
    "   processing very long documents, non-trivial causal and temporal dependencies, and rich discourse structures. \n",
    "   To facilitate future work, we trained and evaluated multiple extractive and abstractive summarization models as baselines for our dataset.\n",
    "''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0, 50118,   133,  1647,     9,   577,  2788, 39186,  1938, 42532,\n",
       "           680,   765,    12,  3899,  1300,  2339,    14,  1762,  1437, 50118,\n",
       "          3479,    12,  9435, 41214,     8, 41853, 45371,     6,     8,   747,\n",
       "          5585,   670, 18472,     8, 15240,  5580, 31681,     4,   616,  4249,\n",
       "             6,  1437, 50118, 16918, 42532,    40,   904,  1804,  2019,    13,\n",
       "           499,  6808,     9,  2788, 39186,  1938,  1743,     4,   166,  1100,\n",
       "           209,  1437, 50118, 40512,    30, 10345,  5972, 38182,     6,    10,\n",
       "          2783,     9, 42532,    13,   251,    12,  3899,  7122, 39186,  1938,\n",
       "             4,  1541, 41616,  4865,  1437, 50118, 17747,  2339,    31,     5,\n",
       "         13144, 11170,     6,   215,    25, 19405,     6,  1974,     8,  1652,\n",
       "             6,     8,  1171,  2200, 20372,  2088,     6,  1437, 50118, 19003,\n",
       "          1982, 32933,  5119,    15,   130,  1389,     9, 17227, 42664,     9,\n",
       "          2284,  9600,    35, 17818, 20551,  7285, 20551,     8,  1040,    12,\n",
       "          4483,     4, 50118,    20, 11170,     8,  3184,     9,    84, 41616,\n",
       "          9748,    10,  2216,   278,     9,  2019,    13, 39186,  1938,  1743,\n",
       "             6,    61,   680,    35, 50118,  1437,  1437,  5774,   182,   251,\n",
       "          2339,     6,   786,    12,    90, 16936,  2617, 41214,     8, 41853,\n",
       "         45371,     6,     8,  4066, 19771,  6609,     4,  1437, 50118,  1437,\n",
       "          1437,   598,  9666,   499,   173,     6,    52,  5389,     8, 15423,\n",
       "          1533, 14660,  2088,     8, 20372,  2088, 39186,  1938,  3092,    25,\n",
       "         11909, 38630,    13,    84, 41616,     4, 50118,     2]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_token = tokenizer(sample_text,return_tensors=\"pt\" )['input_ids']# like dictionary\n",
    "X_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tensor = model.generate(X_token)\n",
    "\n",
    "output = tokenizer.decode(output_tensor[0], skip_special_tokens = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('BookSum is a collection of datasets for long-form narrative summarization. '\n",
      " 'The dataset covers novels, plays and stories. It includes highly '\n",
      " 'abstractive, human written summaries on three levels of granularity of '\n",
      " 'increasing difficulty: paragraph-, chapter-, and book-level. The domain and '\n",
      " 'structure of our dataset poses a unique set of challenges for summarization '\n",
      " 'systems.')\n"
     ]
    }
   ],
   "source": [
    "pprint(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeLsum'], use_stemmer=True)\n",
    "#instead of accuracy in classification we use this to measure the rouge score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-1 (Unigram): Score(precision=0.9629629629629629, recall=0.3586206896551724, fmeasure=0.5226130653266332)\n",
      "ROUGE-2 (Bigram): Score(precision=0.8679245283018868, recall=0.3194444444444444, fmeasure=0.46700507614213194)\n",
      "ROUGE-L (Longest Common Subsequence): Score(precision=0.9444444444444444, recall=0.35172413793103446, fmeasure=0.5125628140703516)\n"
     ]
    }
   ],
   "source": [
    "scores = scorer.score(sample_text, output)\n",
    "print(\"ROUGE-1 (Unigram):\", scores['rouge1'])\n",
    "print(\"ROUGE-2 (Bigram):\", scores['rouge2'])\n",
    "print(\"ROUGE-L (Longest Common Subsequence):\", scores['rougeLsum'])\n",
    "#black box model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    pprint (f\" Trainable params: {trainable_params} \\n All params: {all_param} \\n Trainable%: {100 * trainable_params / all_param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' Trainable params: 56033280 \\n'\n",
      " ' All params: 462323712 \\n'\n",
      " ' Trainable%: 12.119923453115033')\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model \n",
    "\n",
    "config = LoraConfig(\n",
    "    r=380,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"Seq2Seq\"\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(model, config)\n",
    "print_trainable_parameters(peft_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModel(\n",
       "  (base_model): LoraModel(\n",
       "    (model): BartForConditionalGeneration(\n",
       "      (model): BartModel(\n",
       "        (shared): Embedding(50264, 1024, padding_idx=1)\n",
       "        (encoder): BartEncoder(\n",
       "          (embed_tokens): Embedding(50264, 1024, padding_idx=1)\n",
       "          (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "          (layers): ModuleList(\n",
       "            (0-11): 12 x BartEncoderLayer(\n",
       "              (self_attn): BartSdpaAttention(\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1024, out_features=380, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=380, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (q_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1024, out_features=380, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=380, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (activation_fn): GELUActivation()\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (decoder): BartDecoder(\n",
       "          (embed_tokens): Embedding(50264, 1024, padding_idx=1)\n",
       "          (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "          (layers): ModuleList(\n",
       "            (0-11): 12 x BartDecoderLayer(\n",
       "              (self_attn): BartSdpaAttention(\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1024, out_features=380, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=380, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (q_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1024, out_features=380, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=380, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (activation_fn): GELUActivation()\n",
       "              (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (encoder_attn): BartSdpaAttention(\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1024, out_features=380, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=380, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (q_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1024, out_features=380, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=380, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (lm_head): Linear(in_features=1024, out_features=50264, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_tensor = peft_model.generate(X_token)\n",
    "peft_output = tokenizer.decode(peft_tensor[0], skip_special_tokens = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-1 (Unigram): Score(precision=0.9629629629629629, recall=0.3586206896551724, fmeasure=0.5226130653266332)\n",
      "ROUGE-2 (Bigram): Score(precision=0.9056603773584906, recall=0.3333333333333333, fmeasure=0.4873096446700508)\n",
      "ROUGE-L (Longest Common Subsequence): Score(precision=0.9629629629629629, recall=0.3586206896551724, fmeasure=0.5226130653266332)\n"
     ]
    }
   ],
   "source": [
    "scores = scorer.score(sample_text, peft_output)\n",
    "print(\"ROUGE-1 (Unigram):\", scores['rouge1'])\n",
    "print(\"ROUGE-2 (Bigram):\", scores['rouge2'])\n",
    "print(\"ROUGE-L (Longest Common Subsequence):\", scores['rougeLsum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('BookSum is a collection of datasets for long-form narrative summarization. '\n",
      " 'Our dataset covers novels, plays and stories. It includes highly '\n",
      " 'abstractive, human written summaries on three levels of granularity of '\n",
      " 'increasing difficulty: paragraph-, chapter-, and book-level. The domain and '\n",
      " 'structure of our dataset poses a unique set of challenges for summarization '\n",
      " 'systems.')\n"
     ]
    }
   ],
   "source": [
    "pprint(peft_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "peft_model generally has higher ROUGE scores across all metrics (precision, recall, and F1 measure) for both unigram (ROUGE-1) and bigram (ROUGE-2) comparisons. This suggests that, based on the ROUGE metric, peft_model is performing better in terms of generating summaries that match reference summaries.\n",
    "\n",
    "The F1 measure is often used as a balance between precision and recall. In this case, peft_model has higher F1 scores, indicating a better balance between precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(peft_model,\"saved_peft_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use \"model = torch.load(\"saved_peft_model\")\" to load the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
